# rvqa

The Relation-VQA dataset is released!

If you have any question, please do not hesitate to contact me.


## Relation-VQA Dataset
The dataset can be download from the links: [[Link 1](https://drive.google.com/file/d/15zrDnagK3qgKYGkVUrnwr0Zrf2Y8VlSA)], [[Link 2](https://drive.google.com/file/d/1x2T7R6XB3pmqCstffhK_Zv7CkKui95wB)]. 

Or you can download the data files one by one:

**The whole dataset**
- [vg_vqa-rel_map_result_0.30.json](https://drive.google.com/file/d/1YoYMvsg7WweMrz1zC-hPFcTNi21G_Srv)
- [vg_vqa-rel_map_result_0.30.txt](https://drive.google.com/file/d/1RJIFFp20x5lXbpGgWxb3AXa3I8ONfoJ4)

**The splitted dataset**
- [vqa_raw_train_0.30.json](https://drive.google.com/file/d/1R3Hdkqx2sSw2B8Z4VIWQzkrjLfJ7-76y)
- [vqa_raw_val_0.30.json](https://drive.google.com/file/d/18K9WjLu4hN1gEgrJaPSlvZopORlxsGtk)
- [vqa_raw_train_val_0.30.json](https://drive.google.com/file/d/1YDhjFxUzd6zRFJxXA7V968eE0PUk8f-l)
- [vqa_raw_test_0.30.json](https://drive.google.com/file/d/1HPjR6uSaUVeftVKwuejRkb_SnmNvm7RK)

**Alias rules**
- [alias_map_dict.json](https://drive.google.com/file/d/1tnEZPtu8lwjFM0WwmpfTE3DIyb_eSF8z)

### Reference
- **Paper on SIGKDD**: http://www.kdd.org/kdd2018/accepted-papers/view/r-vqa-learning-visual-relation-facts-with-semantic-attention-for-visual-que
- **Paper on arXiv**: https://arxiv.org/abs/1805.09701



If you use this project as part of any published research, please acknowledge the following paper.
```
@inproceedings{lu2018rvqa,
	title={R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering.},
	author={Lu, Pan and Ji, Lei and Zhang, Wei and Duan, Nan and Zhou, Ming and Wang, Jianyong},
	booktitle={SIGKDD 2018},
	year={2018}
}
```
